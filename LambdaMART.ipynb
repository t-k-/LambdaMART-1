{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lambdaMART import LambdaMART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(rel, k=None):\n",
    "    i = np.arange(1, len(rel)+1)\n",
    "    gain = (2**rel - 1)/np.log2(i + 1)\n",
    "    if k is not None:\n",
    "        gain = gain[i <= k]\n",
    "    return gain.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idcg(rel, k=None):\n",
    "    rel = np.sort(rel)[::-1]\n",
    "    i = np.arange(1, len(rel)+1)\n",
    "    gain = (2**rel - 1)/np.log2(i + 1)\n",
    "    if k is not None:\n",
    "        gain = gain[i <= k]\n",
    "    return gain.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(rel, k=None):\n",
    "    idcg_value = idcg(rel, k=k)\n",
    "    if idcg_value != 0:\n",
    "        return dcg(rel, k=k) / idcg_value\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_mean(res_table, k=None):\n",
    "    ndcg_val = 0\n",
    "    for qid in res_table['QueryId'].unique():\n",
    "        rel = res_table[res_table['QueryId'] == qid]['rel']\n",
    "        ndcg_val += ndcg(rel, k=k)\n",
    "    return ndcg_val / res_table['QueryId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, rank, qid = load_svmlight_file('data/train.txt', query_id = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test, rank_test, qid_test = load_svmlight_file('data/test.txt', query_id = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique queries in the dataset: 471\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique queries in the dataset: {len(np.unique(qid))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 50\n",
    "sample_queries = random.sample(list(np.unique(qid)), sample_size)\n",
    "qid_from_sample = (qid == sample_queries[0])\n",
    "for idx in sample_queries[1:]:\n",
    "    qid_from_sample |= (qid == idx)\n",
    "df_part = df[qid_from_sample]\n",
    "rank_part = rank[qid_from_sample]\n",
    "qid_part = qid[qid_from_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, cv_idx = train_test_split(np.unique(qid_part), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_has_train_idx = (qid_part == train_idx[0])\n",
    "for idx in train_idx[1:]:\n",
    "    qid_has_train_idx |= (qid_part == idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_has_cv_idx = (qid_part == cv_idx[0])\n",
    "for idx in cv_idx[1:]:\n",
    "    qid_has_cv_idx |= (qid_part == idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_part[qid_has_train_idx]\n",
    "rank_train = rank_part[qid_has_train_idx]\n",
    "qid_train = qid_part[qid_has_train_idx]\n",
    "\n",
    "df_cv = df_part[qid_has_cv_idx]\n",
    "rank_cv = rank_part[qid_has_cv_idx]\n",
    "qid_cv = qid_part[qid_has_cv_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1064"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rank_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LambdaMART(num_trees=100, max_depth=4, learning_rate=0.125)\n",
    "model.fit(df_train, rank_train, qid_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_predictions = model.predict(df_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame({'neg_pred': -cv_predictions, 'QueryId': qid_cv, \n",
    "                       'DocumentId': np.arange(1, len(qid_cv)+1), 'rel': rank_cv})\n",
    "cv_res = cv_res.sort_values(by=['QueryId', 'neg_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3657082528509856"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_mean(cv_res, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'neg_pred': -predictions, 'QueryId': qid_test, 'DocumentId': np.arange(1, len(qid_test)+1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.sort_values(by=['QueryId', 'neg_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[['QueryId', 'DocumentId']].to_csv('ranking_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
